{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d83ecb",
   "metadata": {},
   "source": [
    "# tensor的合併cat(要合併的其他dim size要一樣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ccde63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "a=torch.rand(4,32,8)\n",
    "b=torch.rand(4,32,7)\n",
    "print(torch.cat([a,b],dim=2).shape) #8+7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e2300",
   "metadata": {},
   "source": [
    "# 合併新增(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55374b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3, 32, 32])\n",
      "torch.Size([4, 3, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x1=torch.rand(4,3,32,32)\n",
    "x2=torch.rand(4,3,32,32)\n",
    "x3=torch.rand(4,3,32,32)\n",
    "print(torch.stack([x1,x2],dim=1).shape) #2張\n",
    "print(torch.stack([x1,x2,x3],dim=1).shape) #3張"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae24604",
   "metadata": {},
   "source": [
    "# tensor的拆開(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51718043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3, 32, 32]) torch.Size([1, 4, 3, 32, 32])\n",
      "torch.Size([4, 1, 32, 32]) torch.Size([4, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#固定1張\n",
    "a=torch.rand(2,4,3,32,32)\n",
    "a1,a2=a.split(1,dim=0) #把兩張紙撕成一張一張 hint只能撕成1張不能16 16分\n",
    "print(a1.shape,a2.shape) \n",
    "#分割成自己要的\n",
    "b=torch.rand(4,3,32,32)\n",
    "b1,b2=b.split([1,2],dim=1) #b1配1 b2配2\n",
    "print(b1.shape,b2.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0354a3",
   "metadata": {},
   "source": [
    "# 等分分割(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c96690ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) torch.Size([2, 4]) torch.Size([2, 4]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "c=torch.rand(7,4)\n",
    "c1,c2,c3,c4=c.chunk(4,dim=0) #將dim=0 size拆成4分\n",
    "print(c1.shape,c2.shape,c3.shape,c4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251c66e",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bc649",
   "metadata": {},
   "source": [
    "1、Broadcasting(廣播)也就是自動實現了unsqueeze expand\n",
    "\n",
    "2、Broadcasting能夠實現自動維度擴展，有點像上節學的expandrepeat\n",
    "\n",
    "比如得到的feature maps的維度是[4,32,14,14]，對這些特徵圖加上偏置，bias[32],先對bias進行unsqueeze操作增加維度：[1,32,1,1]，再用expand操作進行擴充[4,32,14,14]。然後兩者就可以相加了。\n",
    "\n",
    "這種情況是可以使用Broadcasting的，可以避免自己手動的寫多個操作，以更高效的方式計算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121134c3",
   "metadata": {},
   "source": [
    "# 相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e14b9593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 14, 14]) torch.Size([4, 32, 14, 14])\n",
      "tensor(True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,32,14,14)\n",
    "b=torch.rand(1,32,1,1)\n",
    "c1=a+b\n",
    "c2=torch.add(a,b)\n",
    "print(c1.shape,c2.shape)\n",
    "# if all elements are same return True\n",
    "# torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
    "# tensor([[ True, False],   [False, True]])\n",
    "print(torch.all(torch.eq(c1,c2)))\n",
    "a=torch.ones(3,4)\n",
    "torch.all(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165ad69",
   "metadata": {},
   "source": [
    "# 相減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23fb4449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 14, 14]) torch.Size([4, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(4,32,14,14)\n",
    "b=torch.rand(1,32,1,1)\n",
    "c1=a-b\n",
    "c2=torch.sub(a,b)\n",
    "print(c1.shape,c2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "716406c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6639, 0.5441, 0.0303, 0.3572],\n",
       "         [0.3065, 0.0443, 0.6757, 0.0376],\n",
       "         [0.9925, 0.8463, 0.6836, 0.4308]]),\n",
       " tensor([0.9233, 0.4465, 0.4740, 0.0923]),\n",
       " tensor([[1.5872, 0.9906, 0.5044, 0.4495],\n",
       "         [1.2297, 0.4908, 1.1497, 0.1298],\n",
       "         [1.9158, 1.2928, 1.1576, 0.5230]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看相加的element結果\n",
    "a=torch.rand(3,4)\n",
    "b=torch.rand(4)\n",
    "c1=a+b\n",
    "c2=torch.add(a,b)\n",
    "print(c1.shape,c2.shape)\n",
    "a,b,c1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d5b6e",
   "metadata": {},
   "source": [
    "# 哈達瑪積(element wise)乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c7d26",
   "metadata": {},
   "source": [
    "跟一般矩陣乘法不同\n",
    "$$\n",
    "\\begin{Bmatrix}\n",
    " a_1&a_2&a_3\\\\\n",
    " a_4&a_5&a_6\\\\\n",
    " \\end{Bmatrix} \n",
    " *\n",
    " \\begin{Bmatrix}\n",
    " b_1&b_2&b_3\\\\\n",
    " b_4&b_5&b_6\\\\\n",
    " \\end{Bmatrix} \n",
    " =\n",
    " \\begin{Bmatrix}\n",
    " a_1b_1&a_2b_2&a_3b_3\\\\\n",
    " a_4b_4&a_5b_5&a_6b_6\\\\\n",
    " \\end{Bmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d988712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2]) torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9161, 0.0338]]),\n",
       " tensor([0.7299, 0.0733]),\n",
       " tensor([[0.6686, 0.0025]]),\n",
       " tensor([[1.2552, 0.4614]]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(1,2)\n",
    "b=torch.rand(2)\n",
    "c1=a*b\n",
    "c2=torch.mul(a,b)\n",
    "c3=a/b\n",
    "c4=torch.div(a,b)\n",
    "print(c1.shape,c2.shape)\n",
    "a,b,c1,c4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0116de",
   "metadata": {},
   "source": [
    "# 矩陣乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391993b5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{Bmatrix}\n",
    " a_1&a_2\\\\\n",
    " a_3&a_4\\\\\n",
    " \\end{Bmatrix} \n",
    " *\n",
    " \\begin{Bmatrix}\n",
    " b_1\\\\\n",
    " b_2\\\\\n",
    " \\end{Bmatrix} \n",
    " =\n",
    " \\begin{Bmatrix}\n",
    " a_1b_1+a_2b_2\\\\\n",
    " a_3b_1+a_4b_2\\\\\n",
    " \\end{Bmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e19840b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(2,1)\n",
    "b=torch.ones(1,2)\n",
    "print(torch.mm(a,b).shape)\n",
    "print(torch.matmul(a,b).shape)\n",
    "print((a@b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d0a6f",
   "metadata": {},
   "source": [
    "dim>2\n",
    "對於高維的Tensor，定義其矩陣乘法僅在最後的兩個維度上，要求前面的維度必須保持一致，就像矩陣的索引一樣。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dada4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 32])\n"
     ]
    }
   ],
   "source": [
    "c = torch.rand(4, 3, 28, 64)\n",
    "d = torch.rand(4, 3, 64, 32)\n",
    "print(torch.matmul(c, d).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ef397",
   "metadata": {},
   "source": [
    "注意，在這種情形下的矩陣相乘，前面的\"矩陣索引維度\"如果符合Broadcasting機制，也會自動做廣播，然後相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "adff0471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 32])\n"
     ]
    }
   ],
   "source": [
    "c1=torch.rand(4,3,28,64)\n",
    "c2=torch.rand(4,1,64,32)\n",
    "print((c1@c2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "34a78da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 9],\n",
      "        [9, 9]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[0.5774, 0.5774],\n",
      "        [0.5774, 0.5774]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.full([2,2],3)\n",
    "b=a.pow(2) \n",
    "print(b)\n",
    "b=b.sqrt()#也可以寫b**0.5\n",
    "print(b)\n",
    "b=b.rsqrt() #開跟號分之一\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a428aa",
   "metadata": {},
   "source": [
    "# 指數與對數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "72c78749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7183, 2.7183],\n",
      "        [2.7183, 2.7183]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1.4427, 1.4427],\n",
      "        [1.4427, 1.4427]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.exp(torch.ones(2,2))\n",
    "print(a)\n",
    "print(torch.log(a)) #nature log ->ln\n",
    "print(torch.log2(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9a4b0",
   "metadata": {},
   "source": [
    "# 近似值操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41532b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(4.) tensor(3.) tensor(0.1400)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(3.14)\n",
    "print(a.floor(),a.ceil(),a.trunc(),a.frac()) #取下，取上，取整數，取小數\n",
    "c=torch.tensor(4.51)\n",
    "print(c.round()) #hint .5不會四捨五入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d993d3c",
   "metadata": {},
   "source": [
    "# 裁剪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc3707",
   "metadata": {},
   "source": [
    "即對Tensor中的元素進行範圍過濾，不符合條件的可以把它變換到範圍內部（邊界）上，常用於梯度裁剪（gradient clipping），即在發生梯度離散或者梯度爆炸時對梯度的處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "255c87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.3450) tensor(2.6305) tensor(5.2362)\n",
      "tensor([[ 5.2362, 13.3450,  8.0211],\n",
      "        [ 4.8081,  2.6305,  7.4908]])\n",
      "tensor([[10.0000, 13.3450, 10.0000],\n",
      "        [10.0000, 10.0000, 10.0000]])\n",
      "tensor([[ 5.2362, 10.0000,  8.0211],\n",
      "        [ 4.8081,  3.0000,  7.4908]])\n"
     ]
    }
   ],
   "source": [
    "grad = torch.rand(2,3)*15 #0~15隨機生成\n",
    "print(grad.max(),grad.min(),grad.median()) #最大、最小、中位數\n",
    "print(grad)\n",
    "print(grad.clamp(10))#小於10都拉成10\n",
    "print(grad.clamp(3,10)) #小於3變成3 大於10變成10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057d517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
